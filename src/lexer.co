# The Coco Lexer. Uses a series of token-matching regexes to attempt
# matches against the beginning of the source code. When a match is found,
# a token is produced, we consume the match, and start again.
# Tokens are in the form:
#
#     ['TAG', 'value', lineNumber = 0]
#
# which is a format that can be fed directly into
# [Jison](http://github.com/zaach/jison) generated [parser](../lib/parser.js).

# The Lexer Object
# ----------------
# Reads a stream of Coco code and divvies it up into tagged tokens.
# Some potential ambiguity in the grammar has been avoided by
# pushing some extra smarts into Lexer.

# Depends on [Rewriter](#rewriter).
{rewrite, able} = require \./rewriter

exports import
  # `lex` is Lexer's one and only public method.
  lex: (
    # Coco source to be parsed into an array of tokens.
    code
    #  - `.rewrite` <br> Suppresses [rewriting](#rewriter) if `false`.
    #  - `.line`    <br> Specifies the starting line. Defaults to `0`.
    options
  # `tokenize` is Lexer's main method. Scan by attempting to match tokens
  # one at a time, using a regular expression anchored at the start of the
  # remaining code, or a custom recursive token-matching method
  # (for interpolations). When the next token has been recorded,
  # we move forward within the code past the token, and begin again.
  ) -> exports{}.tokenize code || '', options || {}
  tokenize: (code, o) ->
    code.=replace(/\r/g '').replace(/\s+$/ '')
    # Stream of parsed tokens,
    # initialized with a DUMMY token to ensure `@last` always exists.
    @tokens = [@last = [\DUMMY '' 0]]
    # The current line.
    @line = o.line | 0
    # The current indentation level, over-indentation and under-outdentation.
    @indent = @indebt = @dedebt = 0
    # The stack of all current indentation levels.
    @indents = []
    # Prepend a newline if the input starts with an indented line,
    # so that INDENT is recorded properly.
    if /^[^\n\S]+(?!#(?!##(?!#)))\S/.test code then code = \\n + code; --@line
    # Check the first character of current `code`, then call appropriate
    # tokenizers based on it. Each tokenizing method is responsible for
    # returning the number of characters it has consumed.
    while code.=slice i
      switch code.charAt 0
      case [' ' \#]
        i = @spaceToken code
      case \\n then i = @lineToken  code
      case \'  then i = @heredocToken code, \' or @singleStringToken code
      case \"  then i = @heredocToken code, \" or @doubleStringToken code
      case \<
        i = @[if \[ is code.charAt 1 then \wordsToken else \literalToken] code
      case \/
        i = if \* is code.charAt 1
        then @commentToken code
        else if \// is code.substr 1 2
        then @heregexToken code
        else @regexToken code or @literalToken code
      case \` then i = @jsToken code
      default i = @identifierToken code or @numberToken code or
                  @literalToken    code or @spaceToken  code
    # Close up all remaining open blocks.
    @dedent @indent
    # Dispose dummy.
    @tokens.shift()
    # Rewrite the token stream unless explicitly asked not to.
    rewrite @tokens if o.rewrite != 0
    @tokens

  #### Tokenizers

  # Matches an identifying literal: variables, keywords, accessors, etc.
  # Check to ensure that JavaScript reserved words aren't being used as
  # identifiers. Because Coco reserves a handful of keywords that are
  # allowed in JavaScript, we're careful not to tag them as keywords when
  # referenced as property names here, so you can still do `jQuery.is()` even
  # though `is` means `===` otherwise.
  identifierToken: ->
    return 0 unless match = IDENTIFIER.exec it
    if at = \@ is (id = match.1).charAt 0
      id.=slice 1
      tag = \THISPROP
    else
      {last} = this
      switch id
      case \own
        break unless last.0 is \FOR and last.1
        last.1 = ''
        return id.length
      case \from
        break unless @tokens[*-2]?.0 is \FOR
        @<<<{-seenFor, +seenFrom}
        return @token(\FROM, id).length
      case \ever
        break unless last.0 is \FOR
        @seenFor = false
        return @token(\EVER, id).length
      case <[ to til ]>
        if @seenFrom
          @<<<{-seenFrom, +seenTo}
          return @token(\TO id).length
        else if last.0 is \STRNUM and /^[-+\d.]/.test last.1
          last <<< 0:\RANGE op:id
          return id.length
      case \by
        if @seenTo
          @seenTo = false
          return @token(\BY id).length
        else if last.0 is \RANGE and last.to
          last.by = true
          return id.length
      case \all
        break unless last.0 is \IMPORT and last.1 is \<<<
        last.1 += \<
        return id.length
      tag = \IDENTIFIER
    colon = match.2
    if at or colon or (if last\:: then @token \DOT \. else last.0 is \DOT)
      (id = new String id).reserved = true if id of FORBIDDEN
    else if id of COCO_KEYWORDS
      switch tag = id.toUpperCase()
      case \FOR    then @seenFor = true; fallthrough
      case \THEN   then @seenFrom = @seenTo = false
      case \IMPORT then id  = \<<<
      case \UNLESS then tag = \IF
      case \UNTIL  then tag = \WHILE
      case <[ CATCH FUNCTION ]> then id = ''
      case <[ NEW DO TYPEOF DELETE    ]> then tag = \UNARY
      case <[ TRUE FALSE NULL VOID    ]> then tag = \LITERAL
      case <[ BREAK CONTINUE DEBUGGER ]> then tag = \STATEMENT
      case <[ IN OF INSTANCEOF ]>
        if tag is not \INSTANCEOF and @seenFor
          if tag is \OF
            @seenTo = true
            id = last.0 is \IDENTIFIER and @tokens[*-2].0 is \, and
                 (@tokens.splice -2 2; last.1)
          @seenFor = false
          tag = \FOR + tag
          break
        if last.1 is \!
          @tokens.pop()
          id = \! + id
        tag = \RELATION
    else if alias = COCO_ALIASES.hasOwnProperty id
      if id is \not and last.alias and last.1 is \===
        last.1 = \!==
        return id.length
      [tag, id] = COCO_ALIASES[id]
    else if id of RESERVED
      @carp "reserved word \"#{id}\""
    else if not last.1 and last.0 of <[ CATCH FUNCTION ]>
      return (last.1 = id).length
    @token tag, id
    @last.alias = true if alias
    @token \: \:       if colon
    match.0.length

  # Matches a number, including decimal, hex and exponential notation.
  numberToken: ->
    return 0 unless match = NUMBER.exec it
    num = match.3 or match.0; {last} = this
    switch num.charAt 0
    case \. then if @able()
      @token \DOT \.; @token \STRNUM, num.slice 1
      return match.0.length
    case \0 then if num.charAt(1) not of ['' \x \.]
      @carp "deprecated octal literal #{num}"
    if radix = match.1
      @carp "invalid radix #{radix}" unless 2 <= radix <= 36
      num = parseInt rnum = match.2, radix
      if isNaN num or num is parseInt rnum.slice(0, -1), radix
        @carp "invalid number #{rnum} in base #{radix}"
    if sign = last.0 is \+- and not last.spaced
      num = last.1 + num
      @tokens.pop()
      @last = last = @tokens[*-1]
    if last.0 is \RANGE and (not last.to or last.by is true)
    then last[if last.to then \by else \to] = num
    else if sign then @token \STRNUM num else @strnum num
    match.0.length

  # Matches a normal string without interpolations.
  singleStringToken: ->
    @carp 'unterminated string' unless str = SIMPLESTR.exec it
    @strnum unlines str.=0
    @countLines(str).length

  # Ensures that quotation marks are balanced within
  # the string's contents, and within nested interpolations.
  doubleStringToken: ->
    str = @balancedString it, \"
    if 0 < str.indexOf \#{ 1
    then @interpolate str.slice(1 -1), unlines
    else @strnum unlines str
    @countLines(str).length

  # Matches heredocs, adjusting indentation to the correct level, as heredocs
  # preserve whitespace, but ignore indentation to the left.
  heredocToken: (code, q) ->
    return 0 unless code.slice(1 3) is q+q and ~end = code.indexOf q+q+q, 3
    txt = code.slice 3 end
    lnl = txt is not doc = txt.replace /\n[^\n\S]*$/ ''
    if ~doc.indexOf \\n
      tabs = /\n[^\n\S]*(?!$)/mg  # non-empty bol
      dent = 0/0
      dent = len unless dent <= len = m.0.length - 1 while m = tabs.exec doc
      doc  = untabify doc, dent
      if doc.charAt(0) is \\n
        doc.=slice 1
        ++@line
    if q is \" and ~doc.indexOf \#{
      @interpolate doc, enlines
    else
      @strnum enlines string doc, q
      @countLines doc
    ++@line if lnl
    txt.length + 6

  # Matches block comments.
  commentToken: ->
    text = it.slice 0 if ~end = it.indexOf \*/ 2 then end + 2 else 9e9
    @token \COMMENT untabify text, @indent
    @token \TERMINATOR \\n
    @countLines(text).length

  # Matches JavaScript interpolated directly into the source via backticks.
  jsToken: ->
    @carp 'unterminated JS literal' unless js = JSTOKEN.exec it
    @token \LITERAL new String untabify (js.=0).slice(1, -1), @indent
    @last.1.js = true
    @countLines(js).length

  # Matches a regular expression literal, aka regex.
  # Lexing regexes is difficult to distinguish from division,
  # so we borrow some basic heuristics from JavaScript.
  regexToken: ->
    # We distinguish it from the division operator using a list of tokens that
    # a regex never immediately follows.
    # Our list becomes shorter when spaced, due to sans-parentheses calls.
    return 0 if @last.0 of <[ LITERAL CREMENT ]> or
                @able true or not re = REGEX.exec it
    @token \LITERAL if re.=0 is \// then '/(?:)/' else re
    @countLines(re).length

  # Matches a multiline and extended regex literal.
  heregexToken: ->
    @carp 'unterminated heregex' unless match = HEREGEX.exec it
    [heregex, body, flags] = match
    if 0 > body.indexOf \#{
      body.=replace(HEREGEX_OMIT, '').replace(/\//g \\\/)
      @token \LITERAL, "/#{ body or '(?:)' }/#{flags}"
      return @countLines(heregex).length
    @token \IDENTIFIER \RegExp; @token \CALL( \(
    {tokens} = this
    for token, i of @interpolate body
      if token.0 is \TOKENS
        if token.1.1?.1 is \?
        then tokens.pop(); flags = token.1
        else tokens.push ...token.1
      else
        val = token.1.replace HEREGEX_OMIT, ''
        continue if i and not val
        val.=replace bs ||= /\\/g, \\\\\
        tokens.push [\STRNUM; string val, \'; token.2]
      tokens.push [\+- \+ tokens[*-1].2]
    tokens.pop()
    if flags
      @token \, \,
      if typeof flags is \string
      then @token \STRNUM, "'#{flags}'"
      else tokens.push ...flags.slice 2 -1
    @token \)CALL \)
    heregex.length

  # Matches a words literal, a syntax sugar for a list of strings.
  wordsToken: ->
    @carp 'unterminated words' unless ~end = it.indexOf \]> 2
    @token \[ \[
    {tokens, line} = this
    for row of it.slice(2 end).split \\n
      if row.match w ||= /\S+/g then for word of that
        tokens.push [\STRNUM; string word, \'; line] <<< {+spaced}
      ++line
    @line = line - 1
    @token \STRNUM "''" unless word
    @token \] \]
    end + 2

  # Matches newlines, indents, and outdents, and determines which is which.
  # If we can detect that the current line is continued onto the next line,
  # then the newline is suppressed:
  #
  #     elements
  #       .each( ... )
  #       .map( ... )
  #
  # Keeps track of the level of indentation, because a single dedent
  # can close multiple indents, so we need to know how far in we happen to be.
  lineToken: ->
    @countLines indent = MULTIDENT.exec(it).0
    {last} = this; last <<< {+eol, +spaced}
    @seenFrom = @seenTo = false
    size = indent.length - 1 - indent.lastIndexOf \\n
    noNewline = LINE_CONTINUER.test it or last.0 of
      <[ +- DOT ASSIGN LOGIC MATH COMPARE RELATION SHIFT IMPORT ]>
    if size - @indebt is @indent
      noNewline or @newline()
      return indent.length
    if size > @indent
      if noNewline
        @indebt = size - @indent
        return indent.length
      @indents.push @token \INDENT size - @indent + @dedebt
      @dedebt = @indebt = 0
    else
      @indebt = 0
      @dedent @indent - size, noNewline
    @indent = size
    indent.length

  # Consumes non-newline whitespaces and a line comment after them if any.
  spaceToken: ->
    # Tag the previous token as being `.spaced`,
    # because there are cases where it makes a difference.
    (match = SPACE.exec it) and (@last.spaced = true; match.0.length)

  # We treat all other single characters as a token. e.g.: `( ) , . !`
  # Multi-character operators are also literal tokens, so that Jison can assign
  # the proper order of operations. There are some symbols that we tag specially
  # here. `;` and newlines are both treated as a TERMINATOR, we distinguish
  # parentheses that indicate a method call from regular parentheses, and so on.
  literalToken: ->
    return 0 unless val = SYMBOL.exec it
    switch tag = val.=0
    case <[ . ?. &. .= ]>              then tag = \DOT
    case <[ + - ]>                     then tag = \+-
    case <[ ! ~ ]>                     then tag = \UNARY
    case <[ === !== < > <= >= == != ]> then tag = \COMPARE
    case <[ && || ]>                   then tag = \LOGIC
    case \?                            then tag = \LOGIC if @last.spaced
    case <[ / % ]>                     then tag = \MATH
    case <[ ++ -- ]>                   then tag = \CREMENT
    case <[ <<<  <<<< ]>               then tag = \IMPORT
    case <[ << >> >>> ]>               then tag = \SHIFT
    case <[  &  |  ^  ]>               then tag = \BITWISE
    case \@                            then tag = \THIS
    case \;                            then tag = \TERMINATOR
    case \?(                           then tag = \CALL(
    case <[ = := += -= *= /= %= &= ^= |= <<= >>= >>>= ]>
      tag = \ASSIGN
      if @last.0 is \LOGIC
        @tokens.pop()
        (val = new String val).logic = @last.1
    case \*
      tag = if @last.0 of <[ [ ( DOT , ; ]> then \STRNUM else \MATH
    case <[ -> ~> => ]> then tag = \FUNC_ARROW; @tagParameters()
    case <[ <- <~    ]> then tag = \BACK_CALL ; @tagParameters()
    default
      switch val
      case \\\\n then ++@line
      case \@@   then @token \IDENTIFIER \arguments
      case \::
        @token \DOT \.; @token \IDENTIFIER \prototype
        @last\:: = true
      default next = true
      return val.length unless next
      switch val.charAt 0
      case \\
        @strnum if \\ is word = val.slice 1 then "'\\\\'" else string word, \'
        return val.length
      case \(
        if val.length > 1
          @token \CALL( \(
          @token \)CALL \)
          return val.length
        tag = \CALL( if @able true
    @token(tag, val).length

  #### Token Manipulators

  # Records a dedent token, or multiple tokens if we happen to be moving back
  # inwards past several recorded indents.
  dedent: (moveOut, noNewline) ->
    while moveOut > 0
      unless idt = @indents[*-1]
        moveOut = 0
      else if idt <= @dedebt
        moveOut -= idt
        @dedebt -= idt
      else
        moveOut -= @token \DEDENT @indents.pop() - @dedebt
        @dedebt  = 0
    @dedebt -= moveOut
    @newline() unless noNewline

  # Generates a newline token. Consecutive newlines get merged together.
  newline: -> @token \TERMINATOR \\n unless @last.0 is \TERMINATOR

  # A source of ambiguity in our grammar used to be parameter lists in function
  # definitions versus argument lists in function calls. Walk backwards, tagging
  # parameters specially in order to make things easier for the parser.
  tagParameters: ->
    return unless @last.0 is \)
    {tokens} = this; level = 1; i = tokens.length - 1
    while tok = tokens[--i]
      switch tok.0
      case <[ ) )CALL ]> then ++level
      case <[ ( CALL( ]>
        break if --level
        if that is \( then tok.0 = \PARAM(; @last.0 = \)PARAM
        return
    void

  # Matches a balanced group such as a double-quoted string. Pass in
  # a series of delimiters, all of which must be nested correctly within the
  # contents of the string. This method allows us to have strings within
  # interpolations within strings, ad infinitum.
  balancedString: (str, end) ->
    stack = [end]; i = 0
    while chr = str.charAt ++i
      if chr is \\ then ++i; continue
      switch end
      case chr
        stack.pop()
        return str.slice 0 i+1 unless end = stack[*-1]
      case \"
        stack.push end = \} if \{ is chr and \# is str.charAt i-1
      case \}
        switch chr
        case [\" \'] then stack.push end = chr
        case \{      then stack.push end = \}
    @carp "missing #{stack.pop()} in a string"

  # Expands variables and expressions inside double-quoted strings or heregexes
  # using Ruby-like notation for substitution of arbitrary expressions.
  #
  #     "Hello #{name.capitalize()}."
  #
  # Will recursively create a new lexer for each interpolation,
  # tokenizing the contents and merging them into the token stream.
  interpolate: (str, nlines) ->
    {line} = this; ts = []; pi = 0; i = -1
    while str.charAt ++i
      if that is \\
        ++i
        continue
      continue unless that is \# and \{ is str.charAt i+1
      if pi < i
        ts.push [\S s = str.slice pi, i; @line]
        @countLines s
      code = @balancedString str.slice(i+1), \}
      pi   = 1 + i += code.length
      continue unless code.=slice 1, -1
      nested = @lex code, {@line, -rewrite}
      nested.pop()
      nested.shift() if nested.0?.0 is \TERMINATOR
      if len = nested.length
        if len > 1
          nested.unshift [\( \( nested[ 0 ].2]
          nested.push    [\) \) nested[len].2]
        ts.push [\TOKENS nested]
      @countLines code
    if pi < str.length
      ts.push [\S s = str.slice pi; @line]
      @countLines s
    ts.unshift [\S '' line] if ts.0?.0 is not \S
    return ts unless nlines?
    {tokens} = this
    tokens.push [\DOT \. line] if @able()
    tokens.push [\(   \( line]
    for t, i of ts
      tokens.push [\+- \+ tokens[*-1].2] if i
      if t.0 is \TOKENS
      then tokens.push ...t.1
      else tokens.push [\STRNUM nlines string t.1, \"; t.2]
    @token \) \)
    ts

  #### Helpers

  # Adds a token to the results,
  # taking note of the line number and returning `value`.
  token: (tag, value) -> @tokens.push @last = [tag, value, @line]; value

  # Records a string/number token, supplying implicit dot if applicable.
  strnum: ->
    @token \DOT \. if @able() or @last\::
    @token \STRNUM it
    void

  # Increments `@line` by the number of newlines in a string.
  countLines: (str) ->
    pos = 0
    ++@line while pos = 1 + str.indexOf \\n pos
    str

  # Checks if the last token is
  #
  # - callable  via explicit parentheses : `f()`
  # - indexable via implicit brackets    : `x''`
  able: -> not @last.spaced and able @tokens, null, it

  # Throws a syntax error with the current line number.
  carp: -> throw SyntaxError "#{it} on line #{ @line + 1 }"

#### String Helpers

# Constructs a string token by escaping quotes and newlines.
string = (body, quote) ->
  return quote + quote unless body
  body.=replace /\\([\s\S])/g, ($0, $1) ->
    if $1 of [\\n quote] then $1 else $0
  .replace /// #{quote} ///g, \\\$&
  quote + body + quote

# Erases all external indentations of specific length.
untabify = (str, len) ->
  if len then str.replace /// \n [^\n\S]{#{len}} ///g, \\n else str

# Erases all newlines and indentations.
unlines = -> it.replace /\n[^\n\S]*/g ''

# Keeps newlines by escaping them.
enlines = -> it.replace /\n/g \\\n

#### Constants

##### Keywords

# Keywords that Coco shares in common with JavaScript.
JS_KEYWORDS = <[
  true false null this void super return throw break continue
  if else for while switch case default try catch finally class extends
  new do delete typeof in instanceof import function debugger
]>

# Coco-only keywords.
COCO_KEYWORDS = JS_KEYWORDS.concat <[ then of unless until ]>
COCO_ALIASES  = not: <[ UNARY !  ]>, is: <[ COMPARE === ]>
              , and: <[ LOGIC && ]>, or: <[ LOGIC   ||  ]>

# The list of keywords that are reserved by JavaScript, but not used.
# We throw a syntax error for these to avoid runtime errors.
RESERVED = <[ var with const let enum export native ]>

# The superset of both JavaScript keywords and reserved words, none of which may
# be used as identifiers or properties.
FORBIDDEN = JS_KEYWORDS.concat RESERVED

##### Regexes

IDENTIFIER = /// ^
  ( @? [$A-Za-z_\x7f-\uffff][$\w\x7f-\uffff]* )
  ( [^\n\S]* : (?![:=]) )?  # Is this a property name?
///
NUMBER = /// ^ (?
: 0x[\da-f]+                                        # hex
| ([1-9]\d?) r ([\da-z]+)                           # any radix
| ( (?:\d+(?:\.\d+)?|\.\d+) (?:e[+-]?\d+)? ) [a-z]* # decimal
) ///i
SYMBOL = /// ^ (?
: [-+*/%&|^:.<>]=   # compound assign / comparison
| \\\S[^\s,;)}\]]*  # word
| ([-+&|:])\1       # {in,de}crement / logic / prototype access
| [-~=]>            # function
| \([^\n\S]*\)      # call
| [!=]==?           # equality
| \.{3}             # splat/yadayadayada
| [?&]\.            # soak/bind access
| <<(?:=|<<?)?      # left shift / import
| >>>?=?            # rite shift
| @@                # arguments shorthand
| \\\n              # continued line
| \?\(              # soak call
| <[-~]             # back call
| \S
) ///
SPACE     = /^(?=.)[^\n\S]*(?:#.*)?/
MULTIDENT = /^(?:\s*#.*)*(?:\n[^\n\S]*)+/
SIMPLESTR = /^'[^\\']*(?:\\.[^\\']*)*'/
JSTOKEN   = /^`[^\\`]*(?:\\.[^\\`]*)*`/

REGEX = /// ^
  / (?!\s)         # disallow leading whitespace
  [^ [ / \n \\ ]*  # every other thing
  (?:
    (?: \\[\s\S]   # anything escaped
      | \[         # character class
           [^ \] \n \\ ]*
           (?: \\[\s\S] [^ \] \n \\ ]* )*
         ]
    ) [^ [ / \n \\ ]*
  )*
  / [imgy]{0,4} (?!\w)
///
HEREGEX      = /// ^ /{3} ([\s\S]+?) /{3} ([imgy]{0,4}) (?!\w) ///
HEREGEX_OMIT = /\s+(?:#.*)?/g

LINE_CONTINUER = /// ^ \s* (?: , | [?&]?\.(?!\.) | :: ) ///
