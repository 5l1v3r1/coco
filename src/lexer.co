# The Coco Lexer. Uses a series of token-matching regexes to attempt
# matches against the beginning of the source code. When a match is found,
# a token is produced, we consume the match, and start again.
# Tokens are in the form:
#
#     ['TAG', 'value', lineNumber = 0]
#
# which is a format that can be fed directly into
# [Jison](http://github.com/zaach/jison) generated [parser](../lib/parser.js).

# The Lexer Object
# ----------------
# Reads a stream of Coco code and divvies it up into tagged tokens.
# Some potential ambiguity in the grammar has been avoided by
# pushing some extra smarts into Lexer.
exports import
  # `lex` is Lexer's one and only public method.
  lex: (
    # Coco source to be parsed into an array of tokens.
    code
    #  - `.rewrite` <br> Suppresses [rewriting](#rewriter) if `false`.
    #  - `.line`    <br> Specifies the starting line. Defaults to `0`.
    options
  # `tokenize` is Lexer's main method. Scan by attempting to match tokens
  # one at a time, using a regular expression anchored at the start of the
  # remaining code, or a custom recursive token-matching method
  # (for interpolations). When the next token has been recorded,
  # we move forward within the code past the token, and begin again.
  ) -> @{}.tokenize code or '', options or {}
  tokenize: (code, o) ->
    code.=replace(/\r/g, '').replace(/\s+$/, '')
    # Stream of parsed tokens,
    # initialized with a DUMMY token to ensure `@last` always exists.
    @tokens = [@last = [\DUMMY, '', 0]]
    # The current line.
    @line = o.line or 0
    # The current indentation level, over-indentation and under-outdentation.
    @indent = @indebt = @dedebt = 0
    # The stack of all current indentation levels.
    @indents = []
    # Flags for distinguishing FORIN/FOROF/FROM/TO/BY.
    @seenFor = @seenFrom = @seenRange = false
    # Prepend a newline if the input starts with an indented line.
    if /^[^\n\S]+(?!#(?!##[^#]))\S/.test code then code = \\n + code; --@line
    # Check the first character of current `code`, then call appropriate
    # tokenizers based on it. Each tokenizing method is responsible for
    # returning the number of characters it has consumed.
    while code.=slice i
      switch code.charAt 0
      case ' ' then i = @spaceToken code
      case \\n then i = @lineToken  code
      case \'  then i = @heredocToken(code, \') or @singleStringToken code
      case \"  then i = @heredocToken(code, \") or @doubleStringToken code
      case \<
        i = if \[ is code.charAt 1
        then @wordsToken code else @literalToken code
      case \/
        i = if \// is code.substr 1, 2
        then @heregexToken code else @regexToken(code) or @literalToken(code)
      case \# then i = @spaceToken(code) or @commentToken(code)
      case \` then i = @jsToken code
      default i = @identifierToken(code) or @numberToken(code) or
                  @literalToken(code)    or @spaceToken(code)
    # Close up all remaining open blocks.
    @dedent @indent
    # Dispose dummy.
    @tokens.shift()
    # [Rewrite](#rewriter) the token stream unless explicitly asked not to.
    require(\./rewriter).rewrite @tokens if o.rewrite != 0
    @tokens

  #### Tokenizers

  # Matches an identifying literal: variables, keywords, accessors, etc.
  # Check to ensure that JavaScript reserved words aren't being used as
  # identifiers. Because Coco reserves a handful of keywords that are
  # allowed in JavaScript, we're careful not to tag them as keywords when
  # referenced as property names here, so you can still do `jQuery.is()` even
  # though `is` means `===` otherwise.
  identifierToken: ->
    return 0 unless match = IDENTIFIER.exec it
    switch id = match.1
    case \own
      break unless @last.0 is \FOR and @last.1
      @last.1 = ''
      return id.length
    case \from
      break unless @tokens[*-2]?.0 is \FOR
      @seenFor  = false
      @seenFrom = true
      return @token(\FROM, id).length
    case \ever
      break unless @last.0 is \FOR
      @seenFor = false
      return @token(\EVER, id).length
    case <[ to til ]>
      break unless @seenFrom
      @seenFrom  = false
      @seenRange = true
      return @token(\TO, id).length
    case \by
      break unless @seenRange
      @seenRange = false
      return @token(\BY, id).length
    case \all
      break unless @last.0 is \IMPORT and @last.1 is \<<<
      @last.1 += \<
      return id.length
    tag = if at = id.charAt(0) is \@
    then id.=slice 1; \THISPROP
    else              \IDENTIFIER
    [input, [], colon] = match
    forcedIdentifier = at or colon or
      if not (prev = @last).spaced and prev.1.colon2
      then @token \DOT, \.
      else prev.0 is \DOT
    if forcedIdentifier
      (id = new String id).reserved = true if id of FORBIDDEN
    else if id of COCO_KEYWORDS
      switch tag = id.toUpperCase()
      case \FOR    then @seenFor = true
      case \IMPORT then id  = \<<<
      case \UNLESS then tag = \IF
      case \UNTIL  then tag = \WHILE
      case <[ NEW DO TYPEOF DELETE    ]> then tag = \UNARY
      case <[ TRUE FALSE NULL VOID    ]> then tag = \LITERAL
      case <[ BREAK CONTINUE DEBUGGER ]> then tag = \STATEMENT
      case <[ IN OF INSTANCEOF ]>
        if tag isnt \INSTANCEOF and @seenFor
          if tag is \OF
            @seenRange = true
            id = prev.0 is \IDENTIFIER and @tokens[*-2].0 is \, and
                 (@tokens.splice -2, 2; prev.1)
          @seenFor = false
          tag = \FOR + tag
          break
        if @last.1 is \!
          @tokens.pop()
          id = \! + id
        tag = \RELATION
      @seenRange = false if @seenRange and tag of <[ FOR THEN ]>
    else if COCO_ALIASES.hasOwnProperty id then [tag, id] = COCO_ALIASES[id]
    else if id of RESERVED                 then @carp "reserved word \"#{id}\""
    @token tag, id
    @token \:, \: if colon
    input.length

  # Matches a number, including decimal, hex and exponential notation.
  numberToken: ->
    return 0 unless match = NUMBER.exec it
    num = match.3 or match.0
    switch num.charAt 0
    case \. then if @callable() or @last.0 of <[ } LITERAL ]>
      @token \DOT, \.; @token \STRNUM, num.slice 1
      return match.0.length
    case \0 then if num.charAt(1) not of ['', \x, \.]
      @carp "octal literal #{num} is deprecated"
    if radix = match.1
      @carp "invalid radix #{radix}" unless 2 <= radix <= 36
      num = parseInt rnum = match.2, radix
      if isNaN(num) or num is parseInt rnum.slice(0, -1), radix
        @carp "invalid number #{rnum} in base #{radix}"
    @token \STRNUM, num
    match.0.length

  # Matches a normal string. Ensures that quotation marks are balanced within
  # the string's contents, and within nested interpolations.
  singleStringToken: ->
    @carp 'unterminated string' unless str = SIMPLESTR.exec it
    @token \STRNUM, (str.=0).replace MULTILINER, \\\\n
    @countLines(str).length

  doubleStringToken: ->
    str = @balancedString it, \"
    if 0 < str.indexOf \#{, 1
    then @interpolateString str.slice(1, -1), ''
    else @token \STRNUM, str.replace MULTILINER, ''
    @countLines(str).length

  # Matches heredocs, adjusting indentation to the correct level, as heredocs
  # preserve whitespace, but ignore indentation to the left.
  heredocToken: (code, q) ->
    return 0 unless code.slice(1, 3) is q+q and ~end = code.indexOf q+q+q, 3
    txt = code.slice 3, end
    lnl = txt isnt doc = txt.replace /\n[^\n\S]*$/, ''
    if ~doc.indexOf \\n
      tabs = /\n[^\n\S]*(?!$)/mg  # non-empty bol
      dent = 0/0
      dent = len unless dent <= len = m.0.length - 1 while m = tabs.exec doc
      doc  = untabify doc, dent
      if doc.charAt(0) is \\n
        doc.=slice 1
        ++@line
    if q is \" and ~doc.indexOf \#{
      @interpolateString doc, \\\n
    else
      @token \STRNUM, string doc, q, \\\n
      @countLines doc
    ++@line if lnl
    txt.length + 6

  # Matches block comments.
  commentToken: ->
    text = it.slice 3, if ~end = it.indexOf \###, 3 then end else 9e9
    @token \COMMENT, untabify text, @indent
    @token \TERMINATOR, \\n
    @countLines(text).length + 6

  # Matches JavaScript interpolated directly into the source via backticks.
  jsToken: ->
    @carp 'unterminated JS literal' unless js = JSTOKEN.exec it
    (js = new String js.0.slice 1, -1).js = true
    @countLines(@token \LITERAL, js).length + 2

  # Matches a regular expression literal, aka regex.
  # Lexing regexes is difficult to distinguish from division,
  # so we borrow some basic heuristics from JavaScript.
  regexToken: ->
    # We distinguish it from the division operator using a list of tokens that
    # a regex never immediately follows.
    # Our list becomes shorter when spaced, due to sans-parentheses calls.
    return 0 if (prev = @last).0 of <[ LITERAL CREMENT ]> or
                @callable() or not regex = REGEX.exec it
    @token \LITERAL, if regex.=0 is \// then '/(?:)/' else regex
    @countLines(regex).length

  # Matches a multiline and extended regex literal.
  heregexToken: ->
    @carp 'unterminated heregex' unless match = HEREGEX.exec it
    [heregex, body, flags] = match
    if 0 > body.indexOf \#{
      body.=replace(HEREGEX_OMIT, '').replace(/\//g, \\\/)
      @token \LITERAL, "/#{ body or '(?:)' }/#{flags}"
      return @countLines(heregex).length
    @token \IDENTIFIER, \RegExp; @token \CALL(, \(
    {tokens} = this
    for token, i of @interpolateString body
      if token.0 is \TOKENS
        tokens.push ...token.1
      else
        val = token.1.replace HEREGEX_OMIT, ''
        continue if i and not val
        val.=replace bs ||= /\\/g, \\\\\
        tokens.push [\STRNUM; string val, \', \\\n; token.2]
      tokens.push [\+-, \+, tokens[*-1].2]
    tokens.pop()
    if flags then @token \,, \,; @token \STRNUM, "'#{flags}'"
    @token \), \)
    heregex.length

  # Matches a words literal, a syntax sugar for a list of strings.
  wordsToken: ->
    @carp 'unterminated words' unless ~end = it.indexOf \]>, 2
    @token \[, \[
    for line of it.slice(2, end).split \\n
      if line.match re ||= /\S+/g then for word of that
        @tokens.push [\STRNUM; string word, \'; @line], [\,, \,, @line]
      ++@line
    --@line
    if word then @tokens.pop() else @token \STRNUM, "''"
    @token \], \]
    end + 2

  # Matches newlines, indents, and outdents, and determines which is which.
  # If we can detect that the current line is continued onto the next line,
  # then the newline is suppressed:
  #
  #     elements
  #       .each( ... )
  #       .map( ... )
  #
  # Keeps track of the level of indentation, because a single dedent
  # can close multiple indents, so we need to know how far in we happen to be.
  lineToken: ->
    @countLines indent = MULTIDENT.exec(it).0
    @last.eol  = true
    @seenRange = false
    size = indent.length - 1 - indent.lastIndexOf \\n
    noNewline = LINE_CONTINUER.test(it) or @last.0 of
      <[ +- DOT ASSIGN LOGIC MATH COMPARE RELATION SHIFT IMPORT ]>
    if size - @indebt is @indent
      @newline() unless noNewline
      return indent.length
    if size > @indent
      if noNewline
        @indebt = size - @indent
        return indent.length
      @indents.push @token \INDENT, size - @indent + @dedebt
      @dedebt = @indebt = 0
    else
      @indebt = 0
      @dedent @indent - size, noNewline
    @indent = size
    indent.length

  # Consumes non-newline whitespaces and a line comment after them if any.
  spaceToken: ->
    # Tag the previous token as being `.spaced`,
    # because there are cases where it makes a difference.
    (match = SPACE.exec it) and (@last.spaced = true; match.0.length)

  # We treat all other single characters as a token. e.g.: `( ) , . !`
  # Multi-character operators are also literal tokens, so that Jison can assign
  # the proper order of operations. There are some symbols that we tag specially
  # here. `;` and newlines are both treated as a TERMINATOR, we distinguish
  # parentheses that indicate a method call from regular parentheses, and so on.
  literalToken: ->
    return 0 unless val = SYMBOL.exec it
    switch tag = val.=0
    case \)
      @last.0 = \CALL( if @last.0 is \(
    case <[ -> => ]>
      @tagParameters()
      tag = \FUNC_ARROW
    case <[ = := += -= *= /= %= &= ^= |= <<= >>= >>>= ]>
      tag = \ASSIGN
      if @last.0 is \LOGIC
        @tokens.pop()
        (val = new String val).logic = @last.1
    case <[ . ?. &. .= ]>              then tag = \DOT
    case <[ + - ]>                     then tag = \+-
    case <[ ! ~ ]>                     then tag = \UNARY
    case <[ === !== <= < > >= == != ]> then tag = \COMPARE
    case <[ && || & | ^ ]>             then tag = \LOGIC
    case \?                            then tag = \LOGIC if @last.spaced
    case <[ / % ]>                     then tag = \MATH
    case <[ ++ -- ]>                   then tag = \CREMENT
    case <[ <<<  <<<< ]>               then tag = \IMPORT
    case <[ << >> >>> ]>               then tag = \SHIFT
    case \@                            then tag = \THIS
    case \;                            then tag = \TERMINATOR
    case \*
      tag = if @last.0 of <[ [ ( DOT , ; ]> then \STRNUM else \MATH
    case \::
      @token \DOT, \.
      @token \IDENTIFIER, new String(\prototype) <<< {+colon2}
      fallthrough
    case \\\\n then return val.length
    default
      switch val.charAt 0
      case \@
        @token \IDENTIFIER, \arguments; @token \DOT, \.
        @token \STRNUM, val.slice 1
        return val.length
      case \\
        word = val.slice 1
        @token \STRNUM, if word is \\ then "'\\\\'" else string word, \'
        return val.length
      if val is \( and @callable()
        if @last.0 is \?
          @last[0, 1] = [\CALL(, \?(]
          return val.length
        tag = \CALL(
    @token(tag, val).length

  #### Token Manipulators

  # Records a dedent token, or multiple tokens if we happen to be moving back
  # inwards past several recorded indents.
  dedent: (moveOut, noNewline) ->
    while moveOut > 0
      unless idt = @indents[*-1]
        moveOut = 0
      else if idt <= @dedebt
        moveOut -= idt
        @dedebt -= idt
      else
        moveOut -= @token \DEDENT, @indents.pop() - @dedebt
        @dedebt  = 0
    @dedebt -= moveOut
    @newline() unless noNewline

  # Generates a newline token. Consecutive newlines get merged together.
  newline: -> @token \TERMINATOR, \\n unless @last.0 is \TERMINATOR

  # A source of ambiguity in our grammar used to be parameter lists in function
  # definitions versus argument lists in function calls. Walk backwards, tagging
  # parameters specially in order to make things easier for the parser.
  tagParameters: ->
    return if @last.0 isnt \)
    {tokens} = this; level = 1
    tokens[i = (*) - 1].0 = \)PARAM
    while tok = tokens[--i]
      switch tok.0
      case \)            then ++level
      case <[ ( CALL( ]> then return tok.0 = \PARAM( unless --level
    void

  # Matches a balanced group such as a double-quoted string. Pass in
  # a series of delimiters, all of which must be nested correctly within the
  # contents of the string. This method allows us to have strings within
  # interpolations within strings, ad infinitum.
  balancedString: (str, end) ->
    stack = [end]; i = 0
    while chr = str.charAt ++i
      if chr is \\ then ++i; continue
      switch end
      case chr
        stack.pop()
        return str.slice 0, i+1 unless stack.length
        end = stack[*-1]
        continue
      case \" then stack.push end = '}' if \{ is chr and \# is str.charAt i-1
      case \}
        switch chr
        case \", \' then stack.push end = chr
        case \{     then stack.push end = '}'
    @carp 'missing ' + stack.pop()

  # Expand variables and expressions inside double-quoted strings using
  # Ruby-like notation for substitution of arbitrary expressions.
  #
  #     "Hello #{name.capitalize()}."
  #
  # If it encounters an interpolation, this method will recursively create a
  # new Lexer, tokenize the interpolated contents, and merge them into the
  # token stream.
  interpolateString: (str, newline) ->
    {line} = this; ts = []; pi = 0; i = -1
    while str.charAt ++i
      if that is \\
        ++i
        continue
      continue unless that is \# and str.charAt(i+1) is \{
      if pi < i
        ts.push [\S; s = str.slice pi, i; @line]
        @countLines s
      code = @balancedString str.slice(i+1), '}'
      pi   = 1 + i += code.length
      continue unless code.=slice 1, -1
      nested = @lex code, {@line, -rewrite}
      nested.pop()
      nested.shift() if nested.0?.0 is \TERMINATOR
      if nested.length > 1
        nested.unshift [\(, \(, nested[ 0 ].2]
        nested.push    [\), \), nested[*-1].2]
      ts.push [\TOKENS, nested]
      @countLines code
    if pi < str.length
      ts.push [\S; s = str.slice pi; @line]
      @countLines s
    ts.unshift [\S, '', line] if ts.0?.0 isnt \S
    return ts unless newline?
    {tokens} = this
    tokens.push [\(, \(, line]
    for t, i of ts
      tokens.push [\+-, \+, tokens[*-1].2] if i
      if t.0 is \TOKENS
      then tokens.push ...t.1
      else tokens.push [\STRNUM; string t.1, \", newline; t.2]
    @token \), \)
    ts

  #### Helpers

  # Add a token to the results,
  # taking note of the line number and returning `value`.
  token: (tag, value) -> @tokens.push @last = [tag, value, @line]; value

  # Increments `@line` by the number of newlines in a string.
  countLines: (str) ->
    pos = 0
    ++@line while pos = 1 + str.indexOf \\n, pos
    str

  # Checks if the last token is callable via explicit parentheses.
  callable: ->
    return false if @last.spaced
    switch @last.0
    case <[ IDENTIFIER THISPROP THIS SUPER ] ) ? ]> then true
    case \STRNUM then @tokens[*-2]?.0 is \DOT

  # Throws a syntax error with the current line number.
  carp: -> throw SyntaxError "#{it} on line #{ @line + 1 }"

# Constructs a string token by escaping quotes and newlines.
string = (body, quote, newline) ->
  return quote + quote unless body
  body.=replace /\\([\s\S])/g, ($0, $1) ->
    if $1 of [\\n, quote] then $1 else $0
  .replace /// #{quote} ///g, \\\$&
  body.=replace MULTILINER, newline if newline?
  quote + body + quote

# Erases all external indentation on the left-hand side.
untabify = (str, num) ->
  if num then str.replace /// \n [^\n\S]{#{num}} ///g, \\n else str

#### Constants

# Keywords that Coco shares in common with JavaScript.
JS_KEYWORDS = <[
  true false null this void super return throw break continue
  if else for while switch case default try catch finally class extends
  new do delete typeof in instanceof import function debugger
]>

# Coco-only keywords.
COCO_KEYWORDS = JS_KEYWORDS.concat <[ then of unless until ]>
COCO_ALIASES  = not: <[ UNARY ! ]>, and: <[ LOGIC && ]>, or: <[ LOGIC || ]>
              , is: <[ COMPARE === ]>, isnt: <[ COMPARE !== ]>

# The list of keywords that are reserved by JavaScript, but not used.
# We throw a syntax error for these to avoid runtime errors.
RESERVED = <[ var with const let enum export native ]>

# The superset of both JavaScript keywords and reserved words, none of which may
# be used as identifiers or properties.
FORBIDDEN = JS_KEYWORDS.concat RESERVED

# Token matching regexes.
IDENTIFIER = /// ^
  ( @? [$A-Za-z_\x7f-\uffff][$\w\x7f-\uffff]* )
  ( [^\n\S]* : (?![:=]) )?  # Is this a property name?
///
NUMBER = ///
  ^ 0x[\da-f]+                                        # hex
| ^ ([1-9]\d?) r ([\da-z]+)                           # any radix
| ^ ((?: \d+(\.\d+)? | \.\d+ ) (?:e[+-]?\d+)?) [a-z]* # decimal
///i
SYMBOL = /// ^ (?
: [-+*/%&|^:.<>]=   # compound assign / comparison
| \\\S[^\s,;)}\]]*  # word
| ([-+&|:])\1       # {in,de}crement / logic / prototype access
| [-=]>             # function
| [!=]==?           # equality
| \.{3}             # splat
| [?&]\.            # soak/bind access
| <<<<?             # import
| <<=?              # left shift
| >>>?=?            # rite shift
| @\d+              # argument shorthand
| \\\n              # continued line
| \S
) ///
SPACE     = /^(?=.)[^\n\S]*(?:#(?!##[^#]).*)?/
MULTIDENT = /^(?:\s*#(?!##[^#]).*)*(?:\n[^\n\S]*)+/
SIMPLESTR = /^'[^\\']*(?:\\.[^\\']*)*'/
JSTOKEN   = /^`[^\\`]*(?:\\.[^\\`]*)*`/

# Regex-matching-regexes.
REGEX = /// ^
  / (?! \s )       # disallow leading whitespace
  [^ [ / \n \\ ]*  # every other thing
  (?:
    (?: \\[\s\S]   # anything escaped
      | \[         # character class
           [^ \] \n \\ ]*
           (?: \\[\s\S] [^ \] \n \\ ]* )*
         ]
    ) [^ [ / \n \\ ]*
  )*
  / [imgy]{0,4} (?!\w)
///
HEREGEX      = /// ^ /{3} ([\s\S]+?) /{3} ([imgy]{0,4}) (?!\w) ///
HEREGEX_OMIT = /\s+(?:#.*)?/g

MULTILINER      = /\n/g
LINE_CONTINUER  = /// ^ \s* (?: , | [?&]?\.(?!\.) | :: ) ///
