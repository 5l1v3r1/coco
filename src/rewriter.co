# The Coco language has a good deal of optional syntax, implicit syntax,
# and shorthand syntax. This can greatly complicate a grammar and bloat
# the resulting parse table. Instead of making the parser handle it all, we take
# a series of passes over the token stream, using this **Rewriter** to convert
# shorthand into the unambiguous long form, add implicit indentation and
# parentheses, balance incorrect nestings, and generally clean things up.

# **Rewriter** is used by [Lexer](#lexer),
# directly against its internal array of tokens.

# Rewrite the token stream in multiple passes, one logical filter at
# a time. This could certainly be changed into a single pass through the
# stream, with a big ol' efficient switch, but it's much nicer to work with
# like this. The order of these passes matters--indentation must be
# corrected before implicit parentheses can be wrapped around blocks of code.
exports.rewrite = ->
  expandNumbers rewriteClosingParens ensureBalance \
  addImplicitParentheses addImplicitBraces \
  tagPostfixConditionals addImplicitIndentation closeCalls \
  removeMidExpressionTerminators removeLeadingTerminators it

function detectEnd (tokens, i, ok, go) ->
  levels = 0
  while token = tokens[i]
    if      not levels then return go token, i if ok token, i
    else if 0 > levels then return go token, i-1
    [tag] = token
    if      tag of EXPR_START then ++levels
    else if tag of EXPR_END   then --levels
    ++i
  void

# Dispatch leading terminators that would introduce ambiguity in the grammar.
function removeLeadingTerminators (tokens) ->
  break unless tag is \TERMINATOR for [tag], i of tokens
  tokens.splice 0, i if i
  tokens

# Some blocks occur in the middle of expressions--when we're expecting
# this, remove their trailing terminators.
function removeMidExpressionTerminators (tokens) ->
  i = 1
  while tokens[++i]
    continue unless tokens[i-1].0 is \TERMINATOR
    that.=0
    tokens.splice i-1, 1 if that of EXPR_END or
                            that of <[ ELSE CASE DEFAULT CATCH FINALLY ]>
  tokens

# The lexer has tagged each of the opening parenthesis of
# a call. Match it with its closing pair.
function closeCalls (tokens) ->
  stack = []
  for token of tokens
    switch token.0
    case <[ ( CALL( ]> then stack.push that
    case <[ ) )CALL ]> then stack.pop() is \CALL( and token.0 = \)CALL
  tokens

# Object literals may be written without braces for simple cases.
# Insert the missing braces here to aid the parser.
function addImplicitBraces (tokens) ->
  go = (token, i) -> tokens.splice i, 0, [\} \}, token.2]
  ok = (token, i) ->
    return true  if token.1 is \; or \DEDENT is tag = token.0
    return false if tag not of <[ , TERMINATOR ]>
    one = tokens[i+1]?.0
    if tag is \, then one not of <[ IDENTIFIER STRNUM TERMINATOR ( ]>
    else one isnt \COMMENT and \: isnt
      tokens[if one is \( then 1 + indexOfPair tokens, i+1 else i+2]?.0
  stack = []; i = -1
  while token = tokens[++i]
    unless \: is tag = token.0
      switch
      case tag of EXPR_START
        tag = \{ if tag is \INDENT and tokens[i-1]?.0 is \{
        stack.push [tag, i]
      case tag of EXPR_END
        start = stack.pop()
      continue
    paren = tokens[i-1]?.0 is \)
    continue unless paren and tokens[start.1 - 1]?.0 is \: or # a: (..):
                    tokens[i-2]?.0 is   \:                 or # a: b:
                    stack[ *-1]?.0 isnt \{
    stack.push [\{]
    idx  = if paren then start.1 else i-1
    idx -= 2 while tokens[idx-2]?.0 is \COMMENT
    tokens.splice idx, 0, [\{ \{, token.2]
    detectEnd tokens, ++i+1, ok, go
  tokens

# Methods may be optionally called without parentheses for simple cases.
# Insert the missing parentheses here to aid the parser.
function addImplicitParentheses (tokens) ->
  i = 0
  while token = tokens[++i]
    [tag] = token
    unless (prev = tokens[i-1]).spaced
      switch tag
      case \?        then token.call = true
      case <[ [ { ]> then if able prev.0
        tokens.splice i++, 0, [if tag is \[ then \DOT else \CLONE, '', prev[2]]
      continue
    continue unless prev.call or able prev.0, true
    continue unless token.argument or
      tag of <[ ( [ { ... IDENTIFIER THISPROP THIS STRNUM LITERAL RANGE
                UNARY CREMENT IF TRY CLASS FUNCTION SUPER ]> or
      tag is \+- and not (token.spaced or token.eol) or
      tag of <[ PARAM( FUNC_ARROW ]> and tokens[i-2]?.0 isnt \FUNCTION
    seenSingle = seenClass = false
    tokens.splice --i, 1 if soak = prev.0 is \?
    tokens.splice i++, 0, [\CALL(, if soak then \?( else \(, token.2]
    detectEnd tokens, i, ok, go
  function able (tag, call) ->
    tag of <[ IDENTIFIER THISPROP SUPER THIS ) )CALL ] ]> or
    if call then tag is \STRNUM and tokens[i-2]?.0 is \DOT \
            else tag of <[ } STRNUM LITERAL ]>
  function ok (token, i) ->
    return false if token.argument
    return true  if token.decall or not seenSingle and token.fromThen
    [tag] = token
    {0: pre, eol} = tokens[i-1]
    switch tag
    case \CLASS         then seenClass  := true
    case <[ IF CATCH ]> then seenSingle := true
    return true  if tag is \DOT and (eol or pre is \DEDENT)
    return false if token.generated or pre is \,
    if tag is \INDENT
      return seenClass := false if seenClass
      return pre not of <[ { [ , FUNC_ARROW TRY CATCH FINALLY ]>
    tag of <[ POST_IF FOR WHILE BY TO CASE DEFAULT TERMINATOR ]>
  function go (token, i) ->
    ++i if token.0 is \DEDENT
    tokens.splice i, 0, [\)CALL \), token.2]
  tokens

# Because our grammar is LALR(1), it can't handle some single-line
# expressions that lack ending delimiters. **Rewriter** adds the implicit
# blocks, so it doesn't need to. `)` can close a single-line block,
# but we need to make sure it's balanced.
function addImplicitIndentation (tokens) ->
  ok = (token, i) ->
    switch token.0
    case <[ DEDENT CASE DEFAULT CATCH FINALLY ]> then true
    case \TERMINATOR then token.1 isnt \;
    case \ELSE       then tag of <[ IF THEN ]>
  go = (token, i) ->
    tokens.splice if tokens[i-1].0 is \, then i-1 else i, 0, dedent
  i = -1
  while token = tokens[++i]
    [tag] = token
    if \INDENT is next = tokens[i+1]?.0
      switch
      case tag is \THEN   then tokens[i+1] <<< {+fromThen}; fallthrough
      case token.1 is \do then tokens[i+1] <<< {+argument}
      default continue
      tokens.splice i, 1
      continue
    continue if next is \THEN
    continue unless tag of <[ THEN FUNC_ARROW DEFAULT TRY CATCH FINALLY ]> or
                    tag is \ELSE and next isnt \IF
    indent = [\INDENT, 2, token.2]
    dedent = [\DEDENT, 2, token.2]
    indent.generated = dedent.generated = true
    if tag is \THEN
      tokens.splice --i, 1 if tokens[i-1]?.0 is \TERMINATOR
      tokens[i] = indent import {+fromThen}
    else
      tokens.splice ++i, 0, indent
    switch
    case \, is next = tokens[i+1].0 then --i; fallthrough   # ->,
    case \, is tokens[i+2]?.0       then go 0, i += 2; ++i  # -> 0,
    case next of <[ ( [ { ]> and                            # -> [0],
         \, is tokens[idx = 1 + indexOfPair tokens, i+1]?.0
      go 0, idx; ++i
    default detectEnd tokens, i+1, ok, go
  tokens

# Tag postfix conditionals as such, so that we can parse them with a
# different precedence.
function tagPostfixConditionals (tokens) ->
  ok = ([tag]) -> tag of <[ TERMINATOR INDENT ]>
  go = ([tag]) -> token.0 = \POST_IF if tag isnt \INDENT
  detectEnd tokens, i+1, ok, go if token.0 is \IF for token, i of tokens
  tokens

# Ensure that all listed pairs of tokens are correctly balanced throughout
# the course of the token stream.
function ensureBalance (tokens) ->
  levels = {}; olines = {}
  for token of tokens
    [tag] = token
    for [open, close] of BALANCED_PAIRS
      levels[open] |= 0
      if tag is open
        olines[open] = token.2 if levels[open]++ is 0
      else if tag is close and --levels[open] < 0
        carp 'too many ' + token.1, token.2
  for open, level in levels then if level > 0
    carp 'unclosed ' + open, olines[open]
  tokens

# We'd like to support syntax like this:
#
#     el.click((event) ->
#       el.hide())
#
# In order to accomplish this, move outdents that follow closing parens
# inwards, safely. The steps to accomplish this are:
#
# 1. Check that all paired tokens are balanced and in order.
# 2. Rewrite the stream with a stack: if you see an `EXPR_START`, add it
#    to the stack. If you see an `EXPR_END`, pop the stack and replace
#    it with the inverse of what we've just popped.
# 3. Keep track of "debt" for tokens that we manufacture, to make sure we end
#    up balanced in the end.
# 4. Be careful not to alter array or parentheses delimiters with overzealous
#    rewriting.
function rewriteClosingParens (tokens) ->
  debt  = {}; debt[key] = 0 for key in INVERSES
  stack = []; i = -1
  while token = tokens[++i]
    [tag] = token
    unless tag of EXPR_END
      stack.push token if tag of EXPR_START
      continue
    if debt[inv = INVERSES[tag]] > 0
      --debt[inv]
      tokens.splice i--, 1
      continue
    stoken = stack.pop()
    continue if tag is end = INVERSES[start = stoken.0]
    ++debt[start]
    tok = [end, if start is \INDENT then stoken.1 else end]
    pos = if tokens[i+2]?.0 is start then stack.push stoken; i+3 else i
    tokens.splice pos, 0, tok
  tokens

function expandNumbers (tokens) ->
  i = -1
  while token = tokens[++i]
    switch token.0
    case \STRNUM
      num = '' + token.1
      if ~'+-'.indexOf sign = num.charAt 0
        tokens.splice i++, 0, [\+-, sign, token.2]
        token.1 = num.slice 1
    case \RANGE
      ts = []; lno = token.2
      to = token.to - if token.op is \to then 0 else 1e-15
      for n from +token.1 to to by +token.by or 1
        if 32r100 < ts.push [\STRNUM, n, lno]
          carp 'range limit exceeded', lno
      ts.length or carp 'empty range', lno
      tokens.splice i, 1, ...ts
      i += ts.length - 1
  tokens

function indexOfPair (tokens, i) ->
  level = 1; end = INVERSES[start = tokens[i].0]
  while tokens[++i]
    switch that.0
    case start then ++level
    case end   then return i unless --level
  -1

function carp (msg, lno) -> throw SyntaxError msg + ' on line ' + -~lno

#### Constants

# List of the token pairs that must be balanced.
BALANCED_PAIRS = [
       <[ ( ) ]>
       <[ [ ] ]>
       <[ { } ]>
  <[  CALL( )CALL  ]>
  <[ PARAM( )PARAM ]>
  <[ INDENT DEDENT ]>
]

# The inverse mappings of `BALANCED_PAIRS` we're trying to fix up, so we can
# look things up from either end.
INVERSES = {}
# Tokens that signal the start/end of a balanced pair.
EXPR_START = []
EXPR_END   = []
for [left, rite] of BALANCED_PAIRS
  EXPR_START.push INVERSES[rite] = left
  EXPR_END  .push INVERSES[left] = rite
